{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"libraries\"></a>\n",
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "## for converting images to arrays\n",
    "import os, cv2\n",
    "\n",
    "## for train/test/val split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## for developing a neural network\n",
    "import tensorflow as tf\n",
    "import keras_metrics\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator ## image augmentation\n",
    "\n",
    "## for CNN\n",
    "from keras.layers import Conv2D ## Images are 2D convolutions\n",
    "from keras.layers import MaxPooling2D ## Get max features for 2D image\n",
    "from keras.layers import Flatten ## Convert all the features into 1D matrix\n",
    "from keras.layers import Dense ## connect fully connected layer into ANN\n",
    "\n",
    "## for classifier/model evaluation\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the test/train/validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the csv file with merged descriptions\n",
    "merged_df = pd.read_csv('../merged_data',sep='\\t',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>target</th>\n",
       "      <th>target_class_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004cfab-14fd-4e49-80ba-63a80b6bddd6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>No Lung Opacity / Not Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00313ee0-9eaa-42f4-b0ab-c148ed3241cd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>No Lung Opacity / Not Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00322d4d-1c29-4943-afc9-b6754be640eb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>No Lung Opacity / Not Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003d8fa0-6bf1-40ed-b54c-ac657f8495c5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
       "      <td>264.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lung Opacity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              patientId      x      y  width  height  target  \\\n",
       "0  0004cfab-14fd-4e49-80ba-63a80b6bddd6    NaN    NaN    NaN     NaN       0   \n",
       "1  00313ee0-9eaa-42f4-b0ab-c148ed3241cd    NaN    NaN    NaN     NaN       0   \n",
       "2  00322d4d-1c29-4943-afc9-b6754be640eb    NaN    NaN    NaN     NaN       0   \n",
       "3  003d8fa0-6bf1-40ed-b54c-ac657f8495c5    NaN    NaN    NaN     NaN       0   \n",
       "4  00436515-870c-4b36-a041-de91049b9ab4  264.0  152.0  213.0   379.0       1   \n",
       "\n",
       "              target_class_desc  \n",
       "0  No Lung Opacity / Not Normal  \n",
       "1  No Lung Opacity / Not Normal  \n",
       "2  No Lung Opacity / Not Normal  \n",
       "3                        Normal  \n",
       "4                  Lung Opacity  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge target class descriptions together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "## Convert all the No Lung Opacity/Not Normal classes into Normal as well\n",
    "## as the goal is just to predict pneumonia or no pneumonia\n",
    "\n",
    "merged_df['target_class_desc'][merged_df.target == 0]='Normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>target</th>\n",
       "      <th>target_class_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004cfab-14fd-4e49-80ba-63a80b6bddd6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00313ee0-9eaa-42f4-b0ab-c148ed3241cd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00322d4d-1c29-4943-afc9-b6754be640eb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003d8fa0-6bf1-40ed-b54c-ac657f8495c5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
       "      <td>264.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lung Opacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
       "      <td>562.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lung Opacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00569f44-917d-4c86-a842-81832af98c30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>006cec2e-6ce2-4549-bffa-eadfcd1e9970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00704310-78a8-4b38-8475-49f4573b2dbb</td>\n",
       "      <td>323.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lung Opacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00704310-78a8-4b38-8475-49f4573b2dbb</td>\n",
       "      <td>695.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lung Opacity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              patientId      x      y  width  height  target  \\\n",
       "0  0004cfab-14fd-4e49-80ba-63a80b6bddd6    NaN    NaN    NaN     NaN       0   \n",
       "1  00313ee0-9eaa-42f4-b0ab-c148ed3241cd    NaN    NaN    NaN     NaN       0   \n",
       "2  00322d4d-1c29-4943-afc9-b6754be640eb    NaN    NaN    NaN     NaN       0   \n",
       "3  003d8fa0-6bf1-40ed-b54c-ac657f8495c5    NaN    NaN    NaN     NaN       0   \n",
       "4  00436515-870c-4b36-a041-de91049b9ab4  264.0  152.0  213.0   379.0       1   \n",
       "5  00436515-870c-4b36-a041-de91049b9ab4  562.0  152.0  256.0   453.0       1   \n",
       "6  00569f44-917d-4c86-a842-81832af98c30    NaN    NaN    NaN     NaN       0   \n",
       "7  006cec2e-6ce2-4549-bffa-eadfcd1e9970    NaN    NaN    NaN     NaN       0   \n",
       "8  00704310-78a8-4b38-8475-49f4573b2dbb  323.0  577.0  160.0   104.0       1   \n",
       "9  00704310-78a8-4b38-8475-49f4573b2dbb  695.0  575.0  162.0   137.0       1   \n",
       "\n",
       "  target_class_desc  \n",
       "0            Normal  \n",
       "1            Normal  \n",
       "2            Normal  \n",
       "3            Normal  \n",
       "4      Lung Opacity  \n",
       "5      Lung Opacity  \n",
       "6            Normal  \n",
       "7            Normal  \n",
       "8      Lung Opacity  \n",
       "9      Lung Opacity  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert images to ndarrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note:\n",
    "\n",
    "We are converting images to array because it is more flexible to test on different algorithms when we use arrays. Having a certain file structure as required by Keras might not always be a good idea although it is easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('..','datasets','png_converted_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../datasets/png_converted_files'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_arrays():\n",
    "    \"\"\"\n",
    "    Returns two arrays: \n",
    "        x is an array of resized images\n",
    "        y is an array of labels\n",
    "    \"\"\"\n",
    "\n",
    "    x = [] # images as arrays\n",
    "    y = [] # labels \n",
    "    WIDTH = 128\n",
    "    HEIGHT = 128\n",
    "\n",
    "    #for image in enumerate(merged_df.patientId.head(5000)):\n",
    "    for image in enumerate(merged_df.patientId):    \n",
    "        \n",
    "        img_name = image[1]\n",
    "        image_path = path + '/' + img_name + '.png'\n",
    "\n",
    "        # Read and resize image\n",
    "        full_size_image = cv2.imread(image_path)\n",
    "        gray_image = cv2.cvtColor(full_size_image, cv2.COLOR_BGR2GRAY)\n",
    "        x.append(cv2.resize(gray_image, (WIDTH,HEIGHT), interpolation=cv2.INTER_CUBIC))\n",
    "        \n",
    "        # Labels\n",
    "        index_of_image = image[0]\n",
    "        target_value = merged_df.target.loc[index_of_image]\n",
    "        #print(target_value)\n",
    "        y.append(target_value)\n",
    "\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = image_to_arrays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17, 14, 14, ..., 18, 18, 20],\n",
       "       [16, 14, 14, ..., 17, 17, 18],\n",
       "       [17, 14, 14, ..., 16, 17, 18],\n",
       "       ...,\n",
       "       [14, 13, 13, ..., 16, 19, 23],\n",
       "       [19, 17, 17, ..., 20, 29, 40],\n",
       "       [25, 25, 25, ..., 21, 26, 45]], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set it up as a dataframe if you like\n",
    "df = pd.DataFrame()\n",
    "df[\"labels\"]=y\n",
    "df[\"images\"]=X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving arrays for future use\n",
    "np.savez(\"./data_as_arrays/x_images_arrays\", X)\n",
    "np.savez(\"./data_as_arrays/y_pneumonia_labels\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data_as_arrays/x_images_arrays_all.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7c340eff80ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Load a numpy array (Optinal.. only use when needed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Load npz file containing image arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_npz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data_as_arrays/x_images_arrays_all.npz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_npz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arr_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load binary encoded labels for Pneumonia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data_as_arrays/x_images_arrays_all.npz'"
     ]
    }
   ],
   "source": [
    "## Load a numpy array (Optinal.. only use when needed)\n",
    "# Load npz file containing image arrays\n",
    "x_npz = np.load(\"./data_as_arrays/x_images_arrays_all.npz\")\n",
    "X = x_npz['arr_0']\n",
    "# Load binary encoded labels for Pneumonia\n",
    "y_npz = np.load(\"./data_as_arrays/y_pneumonia_labels_all.npz\")\n",
    "y = y_npz['arr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the array into train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split the data in two sets, 80% for training, 20% for Val/Test)\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X,y, test_size=0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second split the 20% into validation and test sets\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5, random_state=1, \n",
    "                                                stratify=y_test_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23191, 128, 128)\n",
      "(2899, 128, 128)\n",
      "(2899, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(X_train).shape)\n",
    "print(np.array(X_val).shape)\n",
    "print(np.array(X_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving arrays for future use\n",
    "np.savez_compressed(\"./data_as_arrays/x_images\", X)\n",
    "np.savez_compressed(\"./data_as_arrays/y_pneumonia\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note:\n",
    "\n",
    "We will be fitting our model on the training set and predict using the test set. But with neural models, we will be need to tune our models a lot. So, for that it is important to have a validation set as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_array = np.array(X_train)\n",
    "X_test_array = np.array(X_test)\n",
    "X_val_array = np.array(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshape the input arrays such that the values are between 0 and 1\n",
    "X_train_array = X_train_array/255.0\n",
    "X_test_array = X_test_array/255.0\n",
    "X_val_array = X_val_array/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head(5000).target_class_desc.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note:\n",
    "\n",
    "Before computing any model, we need to check the baseline value. We need to do the distribution of the target variable and its baseline value. Baseline score will provide us with minimum level that our model must achieve to be accepted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note:\n",
    "\n",
    "Now, we will compute different models and compare the performance through different evaluation metrics. The first one is a multi-layered perceptron. We will fit a simple neural network and evaluate the performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit a Multi-Layer Perceptron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Our MLP Model\n",
    "neural_model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(128, 128)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu), ## input layer\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu), ## first hidden layer\n",
    "    keras.layers.Dense(32, activation=tf.nn.relu), ## second hidden layer\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid) ## output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compile our model together\n",
    "neural_model.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print the neural model summary\n",
    "neural_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting the model\n",
    "y_pred = neural_model.fit(X_train_array, y_train, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluating the model in the test set\n",
    "test_loss, test_acc = neural_model.evaluate(X_test_array, \n",
    "                                            y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate predictions\n",
    "predictions = neural_model.predict(X_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round predictions\n",
    "rounded_predictions = [round(x[0]) for x in predictions]\n",
    "print(rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions = np.array(rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: \n",
    "Out of 5,000 images taken, \n",
    "1. Our baseline is 0.52\n",
    "2. Our test accuracy is 0.776 \n",
    "3. So, let's normalize the distribution of our target classes such that both classes are evenly distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the multi-layered perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_characters = {0: 'Normal', 1: 'Pneumonia'}\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    plt.figure(figsize = (5,5))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(y_test, rounded_predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Normal', 'Lung Opacity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_mtx, classes)\n",
    "plt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print classification report\n",
    "print(classification_report(y_test, rounded_predictions, \n",
    "                            target_names = classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### AUC/ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, rounded_predictions)\n",
    "print('AUC: %.3f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot random line in the middle\n",
    "fig, ax1 = plt.subplots(1,1, figsize = (5, 5), dpi = 250)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr, tpr, marker='.',\n",
    "        label = 'MLP Model (AUC:%.3f)' % auc)\n",
    "# show the plot\n",
    "ax1.legend(loc = 4)\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report:\n",
    "\n",
    "A number of conclusions can be made from our result.\n",
    "1. As more dataset are included, the precision is drastically decreased with MLP.\n",
    "2. The baseline was 70% and there was a high class imbalance. Still, the precision was very low. \n",
    "3. Lets fix the class imbalance by image augmentation and also fit CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Define static variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image size after resizing\n",
    "img_width, img_height = 128, 128\n",
    "\n",
    "## no of training samples\n",
    "nb_train_samples = len(X_train)\n",
    "\n",
    "## no of validation samples\n",
    "nb_validation_samples = len(X_val)\n",
    "\n",
    "## No of epochs/iterations\n",
    "epochs = 10\n",
    "\n",
    "## batch size in each epoch\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Developing a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize the CNN\n",
    "cnn_model = Sequential()\n",
    "\n",
    "## Step 1 - Convolution (filters)\n",
    "cnn_model.add(Conv2D(32, (3, 3), input_shape = (img_width,img_height,1),\n",
    "                            activation = 'relu'))\n",
    "\n",
    "## Step 2 - Pooling\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "## add another Convolution (filters)\n",
    "cnn_model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "\n",
    "\n",
    "## Step 2 - Pooling (downsize to get non-overlapping areas with max values)\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "## add another Convolution (filters)\n",
    "cnn_model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "\n",
    "## Step 2 - Pooling (downsize to get non-overlapping areas with max values)\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "## Step 3 - Flattening (convert 3D feature matrix to 1D vector)\n",
    "cnn_model.add(Flatten())\n",
    "\n",
    "## Step 4 - Make fully connected layer\n",
    "cnn_model.add(Dense(units = 128, activation = 'relu'))\n",
    "cnn_model.add(Dense(units = 64, activation = 'relu'))\n",
    "cnn_model.add(Dense(units = 32, activation = 'relu'))\n",
    "cnn_model.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compiling the CNN\n",
    "cnn_model.compile(optimizer='adam', loss = 'binary_crossentropy',\n",
    "                  metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the summary\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Although, our model is prepared, we still need to fix the class imbalance. With Image Augmentation, techniques we can create new images from the existing images. Image generator in keras enables us to achieve this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1. / 255, \n",
    "                                   horizontal_flip=True, \n",
    "                                   rotation_range=30,\n",
    "                                  width_shift_range=0.1,\n",
    "                                  height_shift_range=0.1, \n",
    "                                  shear_range=0.15,\n",
    "                                  zoom_range=0.1,\n",
    "                                  channel_shift_range=10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valtest_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Visualizing images after image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fit a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### While fitting the model, we need to reshape the training data set to (128,128,1). Here, 1 represents a grayscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training data geenrator\n",
    "train_generator = train_datagen.flow(X_train_array.reshape(nb_train_samples,img_height,img_width,1),\n",
    "                                     y_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing data geenrator\n",
    "test_generator = valtest_datagen.flow(X_test_array.reshape(nb_validation_samples,img_height,img_width,1),\n",
    "                                      y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## validation data generator\n",
    "validation_generator = valtest_datagen.flow(X_val_array.reshape(nb_validation_samples,img_height,img_width,1),\n",
    "                                            y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit a CNN model\n",
    "simple_cnn = cnn_model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch=nb_train_samples/batch_size,\n",
    "    epochs=3,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples/batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluating the model in the test set\n",
    "simple_cnn_loss, simple_cnn_acc = cnn_model.evaluate(X_test_array.\n",
    "                                                     reshape(nb_validation_samples,img_height,img_width,1),\n",
    "                                                     y_test)\n",
    "#test_loss, test_acc = evaluate(X_test_array, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate predictions\n",
    "predictions = cnn_model.predict(X_test_array.\n",
    "                               reshape(nb_validation_samples,img_height,img_width,1))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rounded_predictions(predictions, threshold):\n",
    "    rounded_predictions = []\n",
    "    for x in predictions:\n",
    "        if x[0] > threshold:\n",
    "            rounded_predictions.append(1)\n",
    "        else:\n",
    "            rounded_predictions.append(0)\n",
    "    return rounded_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round predictions\n",
    "rounded_predictions = get_rounded_predictions(predictions, 0.51)\n",
    "\n",
    "#rounded_predictions = [round(x[0]) for x in predictions]\n",
    "print(rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions = np.array(rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the simple cnn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(y_test, rounded_predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_mtx, classes)\n",
    "plt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print classification report\n",
    "print(classification_report(y_test, rounded_predictions, \n",
    "                            target_names = classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### AUC/ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, rounded_predictions)\n",
    "print('AUC: %.3f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot random line in the middle\n",
    "fig, ax1 = plt.subplots(1,1, figsize = (5, 5), dpi = 250)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr, tpr, marker='.',\n",
    "        label = 'Simple CNN Model (AUC:%.3f)' % auc)\n",
    "# show the plot\n",
    "ax1.legend(loc = 4)\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using VGG-16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_images():\n",
    "    \"\"\"\n",
    "    Returns two arrays: \n",
    "        x is an array of resized images\n",
    "        y is an array of labels\n",
    "    \"\"\"\n",
    "\n",
    "    x = [] # images as arrays\n",
    "    y = [] # labels \n",
    "    WIDTH = 224\n",
    "    HEIGHT = 224\n",
    "\n",
    "    #for image in enumerate(merged_df.patientId.head(5000)):\n",
    "    for image in enumerate(merged_df.patientId):    \n",
    "        \n",
    "        img_name = image[1]\n",
    "        image_path = path + '/' + img_name + '.png'\n",
    "\n",
    "        # Read and resize image\n",
    "        full_size_image = cv2.imread(image_path)\n",
    "        x.append(cv2.resize(full_size_image, (WIDTH,HEIGHT), interpolation=cv2.INTER_CUBIC))\n",
    "        \n",
    "        # Labels\n",
    "        index_of_image = image[0]\n",
    "        target_value = merged_df.target.loc[index_of_image]\n",
    "        #print(target_value)\n",
    "        y.append(target_value)\n",
    "\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = proc_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving arrays for future use\n",
    "np.savez_compressed(\"./data_as_arrays/x_images_224\", X)\n",
    "np.savez_compressed(\"./data_as_arrays/y_pneumonia_224\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split the data in two sets, 80% for training, 20% for Val/Test)\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X,y, test_size=0.2, random_state=1, stratify=y)\n",
    "\n",
    "# Second split the 20% into validation and test sets\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5, random_state=1, \n",
    "                                                stratify=y_test_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_array = np.array(X_train)\n",
    "X_test_array = np.array(X_test)\n",
    "X_val_array = np.array(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshape the input arrays such that the values are between 0 and 1\n",
    "X_train_array = X_train_array/255.0\n",
    "X_test_array = X_test_array/255.0\n",
    "X_val_array = X_val_array/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define static variables\n",
    "\n",
    "## Image size after resizing\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "## no of training samples\n",
    "nb_train_samples = len(X_train)\n",
    "\n",
    "## no of validation samples\n",
    "nb_validation_samples = len(X_val)\n",
    "\n",
    "## No of epochs/iterations\n",
    "epochs = 10\n",
    "\n",
    "## batch size in each epoch\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "\n",
    "# params we will probably want to do some hyperparameter optimization later\n",
    "BASE_MODEL= 'VGG16' # ['VGG16', 'RESNET52', 'InceptionV3', 'Xception', 'DenseNet169', 'DenseNet121']\n",
    "IMG_SIZE = (224, 224) # [(224, 224), (384, 384), (512, 512), (640, 640)]\n",
    "BATCH_SIZE = 24 # [1, 8, 16, 24]\n",
    "DENSE_COUNT = 128 # [32, 64, 128, 256]\n",
    "DROPOUT = 0.25 # [0, 0.25, 0.5]\n",
    "LEARN_RATE = 1e-4 # [1e-4, 1e-3, 4e-3]\n",
    "TRAIN_SAMPLES = 8000 # [3000, 6000, 15000]\n",
    "TEST_SAMPLES = 800\n",
    "USE_ATTN = False # [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the base pre-trained model\n",
    "vgg16_model = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the summary statistics to check the structure of the network\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the type of model\n",
    "type(vgg16_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert into Sequential model since our model is sequential\n",
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg16_model.layers[:-1]:\n",
    "    print(layer)\n",
    "    model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note:\n",
    "We can see that there is no difference in the layers except for the last layer.\n",
    "Now, checking at the network, we can see that there are 1000 classes in the predictions layers. But since, we need only need 1 output. So, we need to change it which is why we did not include it in our new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the layers static\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add our own prediction layer\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the VGG16 model in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image Augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255, horizontal_flip=True, rotation_range=30)\n",
    "valtest_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generte training data\n",
    "train_generator = train_datagen.flow(np.array(X_train).\n",
    "                                     reshape(nb_train_samples,img_height,img_width,3),\n",
    "                                     y_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Validation dataset\n",
    "validation_generator = valtest_datagen.flow(np.array(X_val).\n",
    "                                            reshape(nb_validation_samples,img_height,img_width,3),\n",
    "                                            y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate test dataset\n",
    "test_generator = valtest_datagen.flow(np.array(X_test).\n",
    "                                      reshape(nb_validation_samples,img_height,img_width,3),\n",
    "                                      y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the model\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 5,\n",
    "    #steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=3,\n",
    "    validation_data=validation_generator,\n",
    "    #validation_steps=nb_validation_samples // batch_size\n",
    "    validation_steps = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluating the model in the test set\n",
    "vgg16_loss, vgg16_acc = model.evaluate(X_test_array,y_test)\n",
    "#test_loss, test_acc = evaluate(X_test_array, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate predictions\n",
    "predictions = model.predict(X_test_array.\n",
    "                               reshape(nb_validation_samples,img_height,img_width,3))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## round predictions\n",
    "rounded_predictions = get_rounded_predictions(predictions, 0.5)\n",
    "\n",
    "#rounded_predictions = [round(x[0]) for x in predictions]\n",
    "print(rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert the list into array\n",
    "rounded_predictions = np.array(rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the shape to confirm it \n",
    "rounded_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the shape of prediction values in test set\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the simple cnn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(y_test, rounded_predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_mtx, classes)\n",
    "plt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print classification report\n",
    "print(classification_report(y_test, rounded_predictions, \n",
    "                            target_names = classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### AUC/ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, rounded_predictions)\n",
    "print('AUC: %.3f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot random line in the middle\n",
    "fig, ax1 = plt.subplots(1,1, figsize = (5, 5), dpi = 250)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr, tpr, marker='.',\n",
    "        label = 'Simple CNN Model (AUC:%.3f)' % auc)\n",
    "# show the plot\n",
    "ax1.legend(loc = 4)\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
